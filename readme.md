## run
training

```
python3 make_sentens.py -training
```


resume training

```
python3 make_sentens.py --training --resume
```


## architecher

### encoder

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, None, 128)         0
_________________________________________________________________
dense_1 (Dense)              (None, None, 128)         16512
_________________________________________________________________
bidirectional_1 (Bidirection (None, None, 512)         788480
_________________________________________________________________
lstm_2 (LSTM)                [(None, 256), (None, 256) 787456
=================================================================
Total params: 1,592,448
Trainable params: 1,592,448
Non-trainable params: 0
_________________________________________________________________
```


### decoder

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_4 (InputLayer)            (None, None, 128)    0
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, None, 128)    16512       input_4[0][0]
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, None, 512)    788480      dense_2[0][0]
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 256)          0
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 256)          0
__________________________________________________________________________________________________
lstm_4 (LSTM)                   [(None, None, 256),  787456      bidirectional_2[0][0]
                                                                 input_2[0][0]
                                                                 input_3[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, None, 128)    32896       lstm_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 128)    0           dense_3[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, None, 128)    16512       dropout_1[0][0]
==================================================================================================
Total params: 1,641,856
Trainable params: 1,641,856
Non-trainable params: 0
__________________________________________________________________________________________________
```

### context model  (hidden state h in LSTM)

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_5 (InputLayer)            (None, None, 256)    0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 256)          0
__________________________________________________________________________________________________
input_7 (InputLayer)            (None, 256)          0
__________________________________________________________________________________________________
lstm_5 (LSTM)                   [(None, 256), (None, 525312      input_5[0][0]
                                                                 input_6[0][0]
                                                                 input_7[0][0]
==================================================================================================
Total params: 525,312
Trainable params: 525,312
Non-trainable params: 0
__________________________________________________________________________________________________
```

### context model (hidden state c in LSTM)

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_8 (InputLayer)            (None, None, 256)    0
__________________________________________________________________________________________________
input_9 (InputLayer)            (None, 256)          0
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 256)          0
__________________________________________________________________________________________________
lstm_6 (LSTM)                   [(None, 256), (None, 525312      input_8[0][0]
                                                                 input_9[0][0]
                                                                 input_10[0][0]
==================================================================================================
Total params: 525,312
Trainable params: 525,312
Non-trainable params: 0
__________________________________________________________________________________________________
```


### autoencoder

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_11 (InputLayer)           (None, None, 128)    0
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, None, 128)    16512       input_11[0][0]
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, None, 512)    788480      dense_1[1][0]
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, None, 128)    0
__________________________________________________________________________________________________
lstm_2 (LSTM)                   [(None, 256), (None, 787456      bidirectional_1[1][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, None, 128)    16512       input_16[0][0]
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 1, 256)       0           lstm_2[1][1]
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 256)          0
__________________________________________________________________________________________________
input_13 (InputLayer)           (None, 256)          0
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 1, 256)       0           lstm_2[1][2]
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 256)          0
__________________________________________________________________________________________________
input_15 (InputLayer)           (None, 256)          0
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, None, 512)    788480      dense_2[1][0]
__________________________________________________________________________________________________
lstm_5 (LSTM)                   [(None, 256), (None, 525312      reshape_1[0][0]
                                                                 input_12[0][0]
                                                                 input_13[0][0]
__________________________________________________________________________________________________
lstm_6 (LSTM)                   [(None, 256), (None, 525312      reshape_2[0][0]
                                                                 input_14[0][0]
                                                                 input_15[0][0]
__________________________________________________________________________________________________
lstm_4 (LSTM)                   [(None, None, 256),  787456      bidirectional_2[1][0]
                                                                 lstm_5[1][0]
                                                                 lstm_6[1][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, None, 128)    32896       lstm_4[1][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 128)    0           dense_3[1][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, None, 128)    16512       dropout_1[1][0]
==================================================================================================
Total params: 4,284,928
Trainable params: 4,284,928
Non-trainable params: 0
__________________________________________________________________________________________________
```

## input format
Input text  must be given in the form of leaving a space between words.

begin of sentence token : BOS

end of sentence token : 。

```
BOS   部屋 の 四 周 に は 、 窓 や 入口 の ドア さえ 残さ ない で 、 天井 から 床 まで 、 真紅 な 重々しい 垂 絹 が 豊か な 襞 を 作っ て 懸け られ て い た 。
BOS ロマンチック な 蝋燭 の 光 が 、 その 静脈 から 流れ出し た ばかり の 血 の 様 に も 、 ドス 黒い 色 を し た 垂 絹 の 表 に 、 我々 七 人 の 異様 に 大きな 影法師 を 投げ て い た 。
BOS そして 、 その 影法師 は 、 蝋燭 の 焔 に つれ て 、 幾つ か の 巨大 な 昆虫 で も ある か の 様 に 、 垂 絹 の 襞 の 曲線 の 上 を 、 伸び たり 縮ん だり しながら 這い 歩い て い た 。
BOS   いつも ながら その 部屋 は 、 私 を 、 丁度 とほう も なく 大きな 生物 の 心臓 の 中 に 坐っ て でも いる 様 な 気持 に し た 。
BOS 私 に は その 心臓 が 、 大き さ に 相応 し た のろ さ を 以 て 、 ドキンドキン と 脈 うつ 音 さえ 感じ られる 様 に 思え た 。
```

by running aozora_text/all_in_one.sh <args>, you can get the input sentence.

example

``./all_in_one.sh 1779 rnp``

## error
Bug of Keras(2.1.1)??


Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).
